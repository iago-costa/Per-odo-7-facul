{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["import the necessary packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import argparse\n", "import imutils\n", "import cv2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["construct the argument parse and parse the arguments"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ap = argparse.ArgumentParser()\n", "ap.add_argument(\"-m\", \"--model\", required=True,\n", "\thelp=\"path to deep learning segmentation model\")\n", "ap.add_argument(\"-c\", \"--classes\", required=True,\n", "\thelp=\"path to .txt file containing class labels\")\n", "ap.add_argument(\"-i\", \"--image\", required=True,\n", "\thelp=\"path to input image\")\n", "ap.add_argument(\"-l\", \"--colors\", type=str,\n", "\thelp=\"path to .txt file containing colors for labels\")\n", "ap.add_argument(\"-w\", \"--width\", type=int, default=500,\n", "\thelp=\"desired width (in pixels) of input image\")\n", "args = vars(ap.parse_args())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load the class label names"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CLASSES = open(args[\"classes\"]).read().strip().split(\"\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["if a colors file was supplied, load it from disk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if args[\"colors\"]:\n", "\tCOLORS = open(args[\"colors\"]).read().strip().split(\"\\n\")\n", "\tCOLORS = [np.array(c.split(\",\")).astype(\"int\") for c in COLORS]\n", "\tCOLORS = np.array(COLORS, dtype=\"uint8\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["otherwise, we need to randomly generate RGB colors for each class<br>\n", "label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["else:\n", "\t# initialize a list of colors to represent each class label in\n", "\t# the mask\n", "\tnp.random.seed(42)\n", "\tCOLORS = np.random.randint(0, 255, size=(len(CLASSES) - 1, 3),\n", "\t\tdtype=\"uint8\")\n", "\tCOLORS = np.vstack([[0, 0, 0], COLORS]).astype(\"uint8\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initialize the legend visualization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["legend = np.zeros(((len(CLASSES) * 25) + 25, 300, 3), dtype=\"uint8\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["loop over the class names + colors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for (i, (className, color)) in enumerate(zip(CLASSES, COLORS)):\n", "\t# draw the class name + color on the legend\n", "\tcolor = [int(c) for c in color]\n", "\tcv2.putText(legend, className, (5, (i * 25) + 17),\n", "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n", "\tcv2.rectangle(legend, (100, (i * 25)), (300, (i * 25) + 25),\n", "\t\ttuple(color), -1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load our serialized model from disk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net = cv2.dnn.readNet(args[\"model\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load the input image, resize it, and construct a blob from it,<br>\n", "by keeping mind that the original input image dimensions<br>\n", "ENet was trained on was 1024x512"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image = cv2.imread(args[\"image\"])\n", "image = imutils.resize(image, width=args[\"width\"])\n", "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (1024, 512), 0,\n", "\tswapRB=True, crop=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["perform a forward pass using the segmentation model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net.setInput(blob)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output = net.forward()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["infer the total number of classes along with the spatial dimensions<br>\n", "of the mask image via the shape of the output array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(numClasses, height, width) = output.shape[1:4]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["our output class ID map will be num_classes x height x width in<br>\n", "size, so we take the argmax to find the class label with the<br>\n", "largest probability for each and every (x, y)-coordinate in the<br>\n", "image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classMap = np.argmax(output[0], axis=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["given the class ID map, we can map each of the class IDs to its<br>\n", "corresponding color"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mask = COLORS[classMap]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["resize the mask such that its dimensions match the<br>\n", "original size of the input image "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mask = cv2.resize(mask, (image.shape[1], image.shape[0]),\n", "\tinterpolation=cv2.INTER_NEAREST)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["perform a weighted combination of the input image with the mask to<br>\n", "form an output visualization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output = ((0.4 * image) + (0.6 * mask)).astype(\"uint8\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["show the input and output images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv2.imshow(\"Legend\", legend)\n", "cv2.imshow(\"Input\", image)\n", "cv2.imshow(\"Output\", output)\n", "cv2.waitKey(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["USAGE<br>\n", "python segment.py --model enet-cityscapes/enet-model.net --classes enet-cityscapes/enet-classes.txt --colors enet-cityscapes/enet-colors.txt --image images/example_01.png"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}